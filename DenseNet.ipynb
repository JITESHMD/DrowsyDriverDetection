{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b4e1357-8e1d-4206-94c4-0cb2cadbabc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8179241-ed74-4fa9-969e-8ba222ef7f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 06:52:31.400537: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-25 06:52:33.131878: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-25 06:52:33.144973: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-25 06:52:49.747591: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41984472-2b85-4c57-b32d-dae77bb67818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 771 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Set up the data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "train_labels = pd.read_csv('train_img/_annotations.csv')\n",
    "# Convert the column to strings\n",
    "train_labels['class'] = train_labels['class'].astype(str)\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_labels,\n",
    "    directory='train_img',\n",
    "    x_col='filename',\n",
    "    y_col='class',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e8de896-f290-4bbf-a506-5fc80c2c5674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "51877672/51877672 [==============================] - 13s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 06:55:52.913622: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "24/24 [==============================] - 35s 1s/step - loss: 0.6955 - accuracy: 0.6207\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 27s 1s/step - loss: 0.6457 - accuracy: 0.6613\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 27s 1s/step - loss: 0.6417 - accuracy: 0.6658\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 27s 1s/step - loss: 0.6404 - accuracy: 0.6658\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 28s 1s/step - loss: 0.6409 - accuracy: 0.6658\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 28s 1s/step - loss: 0.6394 - accuracy: 0.6667\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 28s 1s/step - loss: 0.6391 - accuracy: 0.6667\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 28s 1s/step - loss: 0.6388 - accuracy: 0.6667\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 28s 1s/step - loss: 0.6385 - accuracy: 0.6667\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 28s 1s/step - loss: 0.6387 - accuracy: 0.6667\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 27s 1s/step - loss: 0.6384 - accuracy: 0.6667\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 28s 1s/step - loss: 0.6384 - accuracy: 0.6667\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 28s 1s/step - loss: 0.6379 - accuracy: 0.6667\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 28s 1s/step - loss: 0.6383 - accuracy: 0.6667\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 27s 1s/step - loss: 0.6378 - accuracy: 0.6667\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 28s 1s/step - loss: 0.6378 - accuracy: 0.6667\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 28s 1s/step - loss: 0.6378 - accuracy: 0.6667\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 28s 1s/step - loss: 0.6377 - accuracy: 0.6667\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 28s 1s/step - loss: 0.6381 - accuracy: 0.6667\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 27s 1s/step - loss: 0.6377 - accuracy: 0.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f56703f78b0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pre-trained DenseNet-169 model and freeze the base layers\n",
    "base_model = tf.keras.applications.DenseNet169(\n",
    "    include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add new fully connected layers on top of the base model\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Compile the model with binary cross-entropy loss and Adam optimizer\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "#freeze Layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2e947f6-292f-4a76-9421-c119ac913251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test CSV file with filenames\n",
    "t_test_df = pd.read_csv(\"test_img/_annotations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3a50f0e-91bb-4bf4-896e-92cd80ec70fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 771 validated image filenames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u190377/tmp/ipykernel_3193743/1759325062.py:14: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  preds = model.predict_generator(t_test_generator, steps=None)\n",
      "2023-04-25 07:07:45.286543: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "# Create a generator for the test images\n",
    "t_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "t_test_generator = t_test_datagen.flow_from_dataframe(\n",
    "    t_test_df,\n",
    "    directory=\"test_img\",\n",
    "    x_col='filename',\n",
    "    y_col=None,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=None,\n",
    "    shuffle=False)\n",
    "\n",
    "# Use the trained model to make predictions on the test data\n",
    "preds = model.predict_generator(t_test_generator, steps=None)\n",
    "# Remove any missing filenames from the test CSV file\n",
    "missing_filenames = set(t_test_generator.filenames) - set(t_test_df['filename'])\n",
    "if missing_filenames:\n",
    "    print(f'Removing {len(missing_filenames)} missing filenames from the test CSV file.')\n",
    "    t_test_df = t_test_df[~t_test_df['filename'].isin(missing_filenames)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67cdd332-7d79-4205-9dca-1d6bc0b6a190",
   "metadata": {},
   "outputs": [],
   "source": [
    "li = []\n",
    "for i in preds.ravel():\n",
    "    if i>0.5:\n",
    "        li.append(1)\n",
    "    else:\n",
    "        li.append(0)\n",
    "     \n",
    "# Create a DataFrame with the filenames and predictions\n",
    "df = pd.DataFrame({'filename': t_test_generator.filenames[:len(preds)], 'class': li})\n",
    "\n",
    "test_inst_df=pd.merge(df, t_test_df, on='filename', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b823d8a4-5442-441a-870f-56093043a380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5136186770428015"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df[\"class\"],t_test_df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "435af66b-74a8-4dfd-ace1-373513b57e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[396, 214, 161],\n",
       "       [  0,   0,   0],\n",
       "       [  0,   0,   0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(df[\"class\"],t_test_df['class']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43baafeb-4fd2-424c-b3ca-0cee0e8c3146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('models2/densenet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8a64fe6-c6e6-4809-a025-2c61119376ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model for Future Inferences\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"densenetmodel.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"densenetmodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "634a8390-3212-4d6b-90ba-4c062db71420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Model from disk\n"
     ]
    }
   ],
   "source": [
    "#Saving Trained Models With h5py\n",
    "from keras.models import model_from_json \n",
    "\n",
    "# opening and store file in a variable\n",
    "\n",
    "json_file = open('densenetmodel.json','r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "\n",
    "# use Keras model_from_json to make a loaded model\n",
    "\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "\n",
    "loaded_model.load_weights(\"densenetmodel.h5\")\n",
    "print(\"Loaded Model from disk\")\n",
    "\n",
    "# compile and evaluate loaded model\n",
    "\n",
    "loaded_model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0f461a-e604-4309-916c-9cc5c277faec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (IntelÂ® oneAPI 2023.0)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
